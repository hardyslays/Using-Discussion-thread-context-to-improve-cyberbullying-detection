{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "data_path = os.getenv(\"DATA_PATH\")\n",
    "model_path = os.getenv(\"MODEL_PATH\") + '/RNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{data_path}/processed/Final_processed_data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'label(CyberBullying,Normal)': 'label'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentIdx = list(data[data['s.no.'] == 1].index)\n",
    "parentIdx.append(len(data))\n",
    "len(parentIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and encode labels\n",
    "labels = data[data['s.no.'] == 1]['label'].values\n",
    "# labels\n",
    "labels = [label.lower().replace(\" \",\"\") for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['s.no.','isParent','authorName','text','likeCount','repliedTo','label'], inplace=True,errors='ignore')\n",
    "data.rename(columns={'negative_prob':'sentiment'},inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating different threads\n",
    "threads = []\n",
    "for i in range(len(parentIdx)-1):\n",
    "    if i == len(parentIdx)-1:\n",
    "        threads.append(data.iloc[parentIdx[i]:].copy())\n",
    "    else:\n",
    "        threads.append(data.iloc[parentIdx[i]:parentIdx[i+1]].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [thread.to_numpy() for thread in threads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'normal':0, 'cyberbullying':1}\n",
    "labels = [label_dict[label] for label in labels]\n",
    "\n",
    "y_data = to_categorical(labels)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the model\n",
    "\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, input_dim , hidden_size , num_layers):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size=input_dim , hidden_size = hidden_size , num_layers= num_layers)\n",
    "        self.fc = nn.Linear(hidden_size,2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x,hn):\n",
    "        out , hn = self.rnn(x, hn)\n",
    "        final_out = self.fc(out[-1])\n",
    "        final_out=self.sig(final_out)\n",
    "        return final_out,hn\n",
    "\n",
    "    def predict(self,x):\n",
    "        hn = self.init()\n",
    "        final_out = self.fc(out[-1])\n",
    "        return final_out\n",
    "\n",
    "    def init(self):\n",
    "        h0 =  torch.zeros(self.num_layers , batch_size , self.hidden_size).to(device)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.count_nonzero(labels)\n",
    "w2 = len(labels) - w1\n",
    "print(w1, \" \", w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train[0].shape[1]\n",
    "\n",
    "device = 'cuda'\n",
    "model = Lstm_model(input_dim , hidden_size , num_layers).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([w1, w2]).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(epoch, X, Y):\n",
    "    h = model.init()\n",
    "    h=h.float()\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for i, x in enumerate(X):\n",
    "    # x is input which is in shape of (seq_len,feature)\n",
    "\n",
    "        y = torch.from_numpy(Y[i]).unsqueeze(0)\n",
    "        y=y.float()\n",
    "\n",
    "        y = y.to(device)\n",
    "\n",
    "        first=x.shape[0]\n",
    "        second=x.shape[1]\n",
    "        x_batch=x.reshape(first,1,second)\n",
    "        x_batch=torch.from_numpy(x_batch)\n",
    "        x_batch=x_batch.float()\n",
    "        \n",
    "        x_batch = x_batch.to(device)\n",
    "\n",
    "        out,h = model(x_batch,h)  \n",
    "        loss = loss_fn(out , y)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss=loss.item()\n",
    "        avg_loss += loss\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, avg_loss / len(X)))\n",
    "\n",
    "def Test(epoch, X, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        h = model.init()\n",
    "        avg_loss = 0\n",
    "        \n",
    "        pred_arr = []\n",
    "        y_arr = []\n",
    "\n",
    "        for i, x in enumerate(x_test):\n",
    "            # x = x.to(device)\n",
    "\n",
    "            first=x.shape[0]\n",
    "            second=x.shape[1]\n",
    "            x_batch=x.reshape(first,1,second)\n",
    "            x_batch=torch.from_numpy(x_batch)\n",
    "            x_batch=x_batch.float()\n",
    "\n",
    "            x_batch = x_batch.to(device)\n",
    "\n",
    "            pred = model(x_batch, h)[0]\n",
    "            # print(pred.numpy())\n",
    "            # pred = scalar.inverse_transform(pred.detach().cpu().numpy()).reshape(-1)\n",
    "            pred_arr = pred_arr + list(pred.detach().cpu().numpy())\n",
    "            y_arr.append(y_test[i])\n",
    "        \n",
    "    pred_vals = np.argmax(pred_arr, axis=1)\n",
    "    y_vals = np.argmax(y_arr, axis=1)\n",
    "    f_score = f1_score(y_vals, pred_vals)\n",
    "    \n",
    "    print('Epoch: {} \\ttest F1 Score: {:.6f}'.format(epoch+1, f_score))\n",
    "\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(model_path+'/best', exist_ok=True)\n",
    "\n",
    "max_f = 0\n",
    "max_i = 0\n",
    "for i in range(epoch):\n",
    "    print(f'Epoch {i+1}: ')\n",
    "    Train(i, x_train, y_train)\n",
    "    f_score = Test(i, x_test, y_test)\n",
    "    f_score = round(f_score, 5)\n",
    "\n",
    "    if f_score > max_f:\n",
    "        max_f = f_score\n",
    "        max_i = i\n",
    "\n",
    "    print('Max F1 Score: {:.6f} on epoch {}'.format(max_f, max_i+1))\n",
    "    filename = \"epoch_\" + str(i+1)+ \"_fscore_\" + str(f_score) + '.tar.pth'\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(model_path+'/', filename))\n",
    "\n",
    "# Saving the best model\n",
    "filename = \"epoch_\" + str(max_i+1)+ \"_fscore_\" + str(max_f) + '.tar.pth'\n",
    "torch.save(model.state_dict(), os.path.join(model_path+'/best/', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the best Model\n",
    "path = model_path+'/best/'\n",
    "filename = \"epoch_\" + str(max_i+1)+ \"_fscore_\" + str(max_f) + '.tar.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(path,filename), map_location=lambda storage, loc: storage))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    h = model.init()\n",
    "    avg_loss = 0\n",
    "    \n",
    "    pred_arr = []\n",
    "    y_arr = []\n",
    "\n",
    "    for i, x in enumerate(x_test):\n",
    "\n",
    "        first=x.shape[0]\n",
    "        second=x.shape[1]\n",
    "        x_batch=x.reshape(first,1,second)\n",
    "        x_batch=torch.from_numpy(x_batch)\n",
    "        x_batch=x_batch.float()\n",
    "\n",
    "        x_batch = x_batch.to(device)\n",
    "\n",
    "        pred = model(x_batch, h)[0]\n",
    "        pred_arr = pred_arr + list(pred.detach().cpu().numpy())\n",
    "        y_arr.append(y_test[i])\n",
    "    \n",
    "pred_vals = np.argmax(pred_arr, axis=1)\n",
    "y_vals = np.argmax(y_arr, axis=1)\n",
    "f_score = f1_score(y_vals, pred_vals)\n",
    "\n",
    "print('test F1 Score: {:.3f}'.format(f_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(y, pred):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1 and pred[i] == 1:\n",
    "            tp += 1\n",
    "        elif y[i] == 0 and pred[i] == 1:\n",
    "            fp += 1\n",
    "        elif y[i] == 0 and pred[i] == 0:\n",
    "            tn += 1\n",
    "        elif y[i] == 1 and pred[i] == 0:\n",
    "            fn += 1\n",
    "    return tp, fp, tn, fn\n",
    "tp, fp, tn, fn = confusion(y_vals, pred_vals)\n",
    "print(tp, fp, '\\n', fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = tp / (tp + fp)\n",
    "print('Precision: {:.3f}%'.format(prec*100))\n",
    "\n",
    "rec = tp / (tp + fn)\n",
    "print('Recall: {:.3f}%'.format(rec*100))\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy: {:.3f}%'.format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
